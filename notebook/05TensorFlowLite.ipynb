{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddda93a8",
   "metadata": {},
   "source": [
    "# TensorFlow Lite Tutorial\n",
    "\n",
    "SPDX-License-Identifier: MIT  \n",
    "SPDX-FileCopyrightText: 2022 Daisuke Sato\n",
    "\n",
    "https://github.com/Tiryoh/mini-pupper-jupyter-notebooks\n",
    "\n",
    "## Reference\n",
    "\n",
    "* https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi\n",
    "* https://gist.github.com/rakelkar/c05bc28f269b154b2a50f20bbdb76cac\n",
    "* https://qengineering.eu/install-tensorflow-2-lite-on-raspberry-64-os.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d373e32e-7684-41e1-bb8c-0fb4702a4cd0",
   "metadata": {},
   "source": [
    "## Download TensorFlow Lite models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7246cce-ebc7-4252-a494-b47fb1cc2719",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd downloads && wget --inet4-only -nc https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip\n",
    "!mkdir -p coco_ssd_mobilenet_v1_1.0_quant_2018_06_29 && unzip -o downloads/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip -d coco_ssd_mobilenet_v1_1.0_quant_2018_06_29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3442cc-68e9-40e4-a4ed-9abf230ad44a",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b733d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_runtime.interpreter import Interpreter\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a9586-c6c3-4bbd-b8c0-bc72af060117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "interpreter = Interpreter(model_path=\"coco_ssd_mobilenet_v1_1.0_quant_2018_06_29/detect.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "height = input_details[0]['shape'][1]\n",
    "width = input_details[0]['shape'][2]\n",
    "floating_model = (input_details[0]['dtype'] == np.float32)\n",
    "\n",
    "input_mean = 127.5\n",
    "input_std = 127.5\n",
    "# Check output layer name to determine if this model was created with TF2 or TF1,\n",
    "# because outputs are ordered differently for TF2 and TF1 models\n",
    "outname = output_details[0]['name']\n",
    "\n",
    "if ('StatefulPartitionedCall' in outname): # This is a TF2 model\n",
    "    boxes_idx, classes_idx, scores_idx = 1, 3, 0\n",
    "else: # This is a TF1 model\n",
    "    boxes_idx, classes_idx, scores_idx = 0, 1, 2\n",
    "\n",
    "print(input_details, output_details, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bb1bb8-e982-44ab-adda-a72d9aef5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the label map\n",
    "with open(\"coco_ssd_mobilenet_v1_1.0_quant_2018_06_29/labelmap.txt\", \"r\") as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Have to do a weird fix for label map if using the COCO \"starter model\" from\n",
    "# https://www.tensorflow.org/lite/models/object_detection/overview\n",
    "# First label is '???', which has to be removed.\n",
    "if labels[0] == '???':\n",
    "    del(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf43df1-f5df-4445-b8ca-e9cd60f2b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417163fd-c7c1-4a7b-9e6a-b05330482f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pakutaso.com/photo/38958.html\n",
    "!cd images && wget --inet4-only -nc https://www.pakutaso.com/shared/img/thumb/ookawa621458A3167_TP_V4.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b059aa46-aec7-445e-aeed-cbc0b21c6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"images/ookawa621458A3167_TP_V4.jpg\"\n",
    "\n",
    "min_conf_threshold = 0.5\n",
    "\n",
    "# Load image and resize to expected shape [1xHxWx3]\n",
    "image_bgr = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "imH, imW, _ = image.shape \n",
    "image_resized = cv2.resize(image, (width, height))\n",
    "input_data = np.expand_dims(image_resized, axis=0)\n",
    "\n",
    "# Normalize pixel values if using a floating model (i.e. if model is non-quantized)\n",
    "if floating_model:\n",
    "    input_data = (np.float32(input_data) - input_mean) / input_std\n",
    "\n",
    "# Perform the actual detection by running the model with the image as input\n",
    "interpreter.set_tensor(input_details[0]['index'],input_data)\n",
    "interpreter.invoke()\n",
    "\n",
    "# Retrieve detection results\n",
    "boxes = interpreter.get_tensor(output_details[boxes_idx]['index'])[0] # Bounding box coordinates of detected objects\n",
    "classes = interpreter.get_tensor(output_details[classes_idx]['index'])[0] # Class index of detected objects\n",
    "scores = interpreter.get_tensor(output_details[scores_idx]['index'])[0] # Confidence of detected objects\n",
    "\n",
    "# Loop over all detections and draw detection box if confidence is above minimum threshold\n",
    "for i in range(len(scores)):\n",
    "    if ((scores[i] > min_conf_threshold) and (scores[i] <= 1.0)):\n",
    "\n",
    "        # Get bounding box coordinates and draw box\n",
    "        # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()\n",
    "        ymin = int(max(1,(boxes[i][0] * imH)))\n",
    "        xmin = int(max(1,(boxes[i][1] * imW)))\n",
    "        ymax = int(min(imH,(boxes[i][2] * imH)))\n",
    "        xmax = int(min(imW,(boxes[i][3] * imW)))\n",
    "\n",
    "        cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)\n",
    "\n",
    "        # Draw label\n",
    "        object_name = labels[int(classes[i])] # Look up object name from \"labels\" array using class index\n",
    "        label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'\n",
    "        labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2) # Get font size\n",
    "        label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n",
    "        cv2.rectangle(image, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Draw white box to put label text in\n",
    "        cv2.putText(image, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2) # Draw label text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d0f2e-481a-4496-ace4-9afd4a53f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the image with matplotlib\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db8c976-80af-4adc-9faa-8173710551b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
