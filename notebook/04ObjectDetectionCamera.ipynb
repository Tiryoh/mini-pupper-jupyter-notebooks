{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddda93a8",
   "metadata": {},
   "source": [
    "# Object Detection with camera\n",
    "\n",
    "SPDX-License-Identifier: MIT  \n",
    "SPDX-FileCopyrightText: 2022 Daisuke Sato\n",
    "\n",
    "https://github.com/Tiryoh/mini-pupper-jupyter-notebooks\n",
    "\n",
    "## Reference\n",
    "\n",
    "* https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d373e32e-7684-41e1-bb8c-0fb4702a4cd0",
   "metadata": {},
   "source": [
    "## Set Network configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c71e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK_INTERFACE=\"eth0\"\n",
    "NETWORK_INTERFACE=\"wlan0\"\n",
    "\n",
    "import netifaces as ni\n",
    "ip_address = ni.ifaddresses(NETWORK_INTERFACE)[ni.AF_INET][0]['addr']\n",
    "print(ip_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set self ip address\n",
    "os.environ['ROS_IP'] = ip_address\n",
    "\n",
    "# Set ROS_MASTER_URI\n",
    "ROS_MASTER_IP=ip_address\n",
    "# ROS_MASTER_IP=\"192.168.10.14\" # modify here to specify custom ip\n",
    "\n",
    "os.environ['ROS_MASTER_URI'] = 'http://{}:11311'.format(ROS_MASTER_IP)\n",
    "print(\"ROS_MASTER_IP is {}\".format(ROS_MASTER_IP))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836590d3-10de-4b11-83e2-ab5c5d2ed3dc",
   "metadata": {},
   "source": [
    "### Check environment  \n",
    "\n",
    "It should outputs like this:\n",
    "\n",
    "```\n",
    "192.168.10.12\n",
    "http://192.168.10.12:11311\n",
    "```\n",
    "\n",
    "If the result is `http://localhost:11311`, re-run the above procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c51641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Env\n",
    "!echo $ROS_IP\n",
    "!echo $ROS_MASTER_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3442cc-68e9-40e4-a4ed-9abf230ad44a",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b733d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sidecar import Sidecar\n",
    "# Using jupyros(jupyter-ros) 0.5.0 from conda for now\n",
    "try:\n",
    "    from jupyros import ros3d\n",
    "except ImportError:\n",
    "    from jupyros.ros1 import ros3d\n",
    "\n",
    "# Check jupyros version\n",
    "import jupyros\n",
    "print(jupyros.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0318e5-defc-44c4-a4bf-a2d35cd9834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_runtime.interpreter import Interpreter\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tflite_runtime\n",
    "print(tflite_runtime.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb93b1a-cf6f-46b7-b0b9-788cec60c914",
   "metadata": {},
   "source": [
    "## Load Tensor Flow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a2e52-2229-4423-be40-a1c7dd63b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "interpreter = Interpreter(model_path=\"coco_ssd_mobilenet_v1_1.0_quant_2018_06_29/detect.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "height = input_details[0]['shape'][1]\n",
    "width = input_details[0]['shape'][2]\n",
    "floating_model = (input_details[0]['dtype'] == np.float32)\n",
    "\n",
    "input_mean = 127.5\n",
    "input_std = 127.5\n",
    "# Check output layer name to determine if this model was created with TF2 or TF1,\n",
    "# because outputs are ordered differently for TF2 and TF1 models\n",
    "outname = output_details[0]['name']\n",
    "\n",
    "if ('StatefulPartitionedCall' in outname): # This is a TF2 model\n",
    "    boxes_idx, classes_idx, scores_idx = 1, 3, 0\n",
    "else: # This is a TF1 model\n",
    "    boxes_idx, classes_idx, scores_idx = 0, 1, 2\n",
    "\n",
    "# un-comment to see the details\n",
    "# print(input_details, output_details, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc2715-a5e6-4134-9ed5-bebc6d9725bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the label map\n",
    "with open(\"coco_ssd_mobilenet_v1_1.0_quant_2018_06_29/labelmap.txt\", \"r\") as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Have to do a weird fix for label map if using the COCO \"starter model\" from\n",
    "# https://www.tensorflow.org/lite/models/object_detection/overview\n",
    "# First label is '???', which has to be removed.\n",
    "if labels[0] == '???':\n",
    "    del(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35daf4e-cc25-4988-8adf-09d99c9ca235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check labels\n",
    "print(len(labels))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52e1902-9c03-4516-a80c-a776eba86427",
   "metadata": {},
   "source": [
    "## Subscribe camera image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa5700-cfef-423b-8e75-3bdb9d736964",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Start camera image publish node\n",
    "\n",
    "Before starting subscriber, we need to start the ROS node to publish camera image.  \n",
    "Open terminal and run `cd ~/dev/mini-pupper-jupyter-notebooks && roslaunch ROS/camera.launch`\n",
    "\n",
    "<img src=\"https://i.gyazo.com/4c1d067e131340e4a15792a08204ef22.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63efe5-5793-437f-9742-5f92b6dba3bc",
   "metadata": {},
   "source": [
    "### Check topic\n",
    "\n",
    "If it shows `ERROR: Unable to communicate with master!` or `ERROR: Unknown topic /image_raw`, re-run the network configuration step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2bd49b-6fb7-4712-8a7a-8eceaa04e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rostopic info /image_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ab5aa-0a7f-483b-a938-2a32aef9b83b",
   "metadata": {},
   "source": [
    "### Create Jupyter widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fb7ddd-fce9-4185-8805-9b3c08859820",
   "metadata": {},
   "source": [
    "First, create an empty widget.\n",
    "\n",
    "<img src=\"https://i.gyazo.com/d219da88864a18ecdbc79b8ed939ab4c.png\" width=\"200px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9426d8-78e6-4291-89c5-dbca39f0ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=600, height=600)\n",
    "try:\n",
    "    sc = Sidecar(title='Object Detection Output')\n",
    "    with sc:\n",
    "        display(widgets.VBox([image_widget]))\n",
    "except:\n",
    "    display(widgets.VBox([image_widget]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eea8b8-1ab0-4ec8-9428-762ea597bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from io import BytesIO\n",
    "\n",
    "import rospy\n",
    "from sensor_msgs.msg import Image\n",
    "\n",
    "ros_msg = Image()\n",
    "bridge = CvBridge()\n",
    "\n",
    "min_conf_threshold = 0.5\n",
    "\n",
    "rospy.init_node(\"image_subscriber\")\n",
    "rate = rospy.Rate(5)\n",
    "\n",
    "def callback(msg):\n",
    "    if rate.remaining() > rospy.Duration(0):\n",
    "        return\n",
    "    try:\n",
    "        image = bridge.imgmsg_to_cv2(msg, \"bgr8\")\n",
    "    except CvBridgeError as e:\n",
    "        rospy.logerr(\"CvBridge Error: {0}\".format(e))\n",
    "\n",
    "    # Load image and resize to expected shape [1xHxWx3]\n",
    "    imH, imW, _ = image.shape \n",
    "    image_resized = cv2.resize(image, (width, height))\n",
    "    input_data = np.expand_dims(image_resized, axis=0)\n",
    "\n",
    "    # Normalize pixel values if using a floating model (i.e. if model is non-quantized)\n",
    "    if floating_model:\n",
    "        input_data = (np.float32(input_data) - input_mean) / input_std\n",
    "\n",
    "    # Perform the actual detection by running the model with the image as input\n",
    "    interpreter.set_tensor(input_details[0]['index'],input_data)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Retrieve detection results\n",
    "    boxes = interpreter.get_tensor(output_details[boxes_idx]['index'])[0] # Bounding box coordinates of detected objects\n",
    "    classes = interpreter.get_tensor(output_details[classes_idx]['index'])[0] # Class index of detected objects\n",
    "    scores = interpreter.get_tensor(output_details[scores_idx]['index'])[0] # Confidence of detected objects\n",
    "\n",
    "    # Loop over all detections and draw detection box if confidence is above minimum threshold\n",
    "    for i in range(len(scores)):\n",
    "        if ((scores[i] > min_conf_threshold) and (scores[i] <= 1.0)):\n",
    "\n",
    "            # Get bounding box coordinates and draw box\n",
    "            # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()\n",
    "            ymin = int(max(1,(boxes[i][0] * imH)))\n",
    "            xmin = int(max(1,(boxes[i][1] * imW)))\n",
    "            ymax = int(min(imH,(boxes[i][2] * imH)))\n",
    "            xmax = int(min(imW,(boxes[i][3] * imW)))\n",
    "\n",
    "            cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)\n",
    "\n",
    "            # Draw label\n",
    "            object_name = labels[int(classes[i])] # Look up object name from \"labels\" array using class index\n",
    "            label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'\n",
    "            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 2.5, 4) # Get font size\n",
    "            label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n",
    "            cv2.rectangle(image, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Draw white box to put label text in\n",
    "            cv2.putText(image, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 2.5, (0, 0, 0), 4) # Draw label text\n",
    "\n",
    "    _, frame = cv2.imencode('.jpg', cv2.resize(image, (int(width), int(height))), [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "    frame_buffer = BytesIO(frame)\n",
    "    image_widget.value = frame_buffer.getvalue()\n",
    "\n",
    "    rate.last_time = rospy.rostime.get_rostime()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf0d0b7-92a1-47a5-b0ca-1636d8b8a3ad",
   "metadata": {},
   "source": [
    "Run the below cell to start subscribing image and updating widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d8562f-fc06-4633-bbdb-60a463da891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyros\n",
    "\n",
    "jupyros.subscribe(\"/image_raw\", Image, callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0543711-8389-49ae-ae2f-2e01224283d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
