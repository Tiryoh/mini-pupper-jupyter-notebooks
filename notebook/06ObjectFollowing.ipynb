{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddda93a8",
   "metadata": {},
   "source": [
    "# Object Following\n",
    "\n",
    "SPDX-License-Identifier: MIT  \n",
    "SPDX-FileCopyrightText: 2022 Daisuke Sato\n",
    "\n",
    "https://github.com/Tiryoh/mini-pupper-jupyter-notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d373e32e-7684-41e1-bb8c-0fb4702a4cd0",
   "metadata": {},
   "source": [
    "## Set Network configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c71e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK_INTERFACE=\"eth0\"\n",
    "NETWORK_INTERFACE=\"wlan0\"\n",
    "\n",
    "import netifaces as ni\n",
    "ip_address = ni.ifaddresses(NETWORK_INTERFACE)[ni.AF_INET][0]['addr']\n",
    "print(ip_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set self ip address\n",
    "os.environ['ROS_IP'] = ip_address\n",
    "\n",
    "# Set ROS_MASTER_URI\n",
    "ROS_MASTER_IP=ip_address\n",
    "# ROS_MASTER_IP=\"192.168.10.14\" # custom\n",
    "\n",
    "os.environ['ROS_MASTER_URI'] = 'http://{}:11311'.format(ROS_MASTER_IP)\n",
    "print(\"ROS_MASTER_IP is {}\".format(ROS_MASTER_IP))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836590d3-10de-4b11-83e2-ab5c5d2ed3dc",
   "metadata": {},
   "source": [
    "### Check environment  \n",
    "\n",
    "It should outputs like this:\n",
    "\n",
    "```\n",
    "192.168.10.23\n",
    "http://192.168.10.14:11311\n",
    "```\n",
    "\n",
    "If the result is `http://localhost:11311`, re-run the above procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c51641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Env\n",
    "!echo $ROS_IP\n",
    "!echo $ROS_MASTER_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3442cc-68e9-40e4-a4ed-9abf230ad44a",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b733d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sidecar import Sidecar\n",
    "# Using jupyros(jupyter-ros) 0.5.0 from conda for now\n",
    "try:\n",
    "    from jupyros import ros3d\n",
    "except ImportError:\n",
    "    from jupyros.ros1 import ros3d\n",
    "\n",
    "# Check jupyros version\n",
    "import jupyros\n",
    "print(jupyros.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0318e5-defc-44c4-a4bf-a2d35cd9834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_runtime.interpreter import Interpreter\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tflite_runtime\n",
    "print(tflite_runtime.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb93b1a-cf6f-46b7-b0b9-788cec60c914",
   "metadata": {},
   "source": [
    "## Load Tensor Flow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a2e52-2229-4423-be40-a1c7dd63b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "interpreter = Interpreter(model_path=\"coco_ssd_mobilenet_v1_1.0_quant_2018_06_29/detect.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "height = input_details[0]['shape'][1]\n",
    "width = input_details[0]['shape'][2]\n",
    "floating_model = (input_details[0]['dtype'] == np.float32)\n",
    "\n",
    "input_mean = 127.5\n",
    "input_std = 127.5\n",
    "# Check output layer name to determine if this model was created with TF2 or TF1,\n",
    "# because outputs are ordered differently for TF2 and TF1 models\n",
    "outname = output_details[0]['name']\n",
    "\n",
    "if ('StatefulPartitionedCall' in outname): # This is a TF2 model\n",
    "    boxes_idx, classes_idx, scores_idx = 1, 3, 0\n",
    "else: # This is a TF1 model\n",
    "    boxes_idx, classes_idx, scores_idx = 0, 1, 2\n",
    "\n",
    "print(input_details, output_details, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc2715-a5e6-4134-9ed5-bebc6d9725bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the label map\n",
    "with open(\"coco_ssd_mobilenet_v1_1.0_quant_2018_06_29/labelmap.txt\", \"r\") as f:\n",
    "    labels = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35daf4e-cc25-4988-8adf-09d99c9ca235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52e1902-9c03-4516-a80c-a776eba86427",
   "metadata": {},
   "source": [
    "## Subscribe camera image and control robot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63efe5-5793-437f-9742-5f92b6dba3bc",
   "metadata": {},
   "source": [
    "### Check topic\n",
    "\n",
    "If it shows `ERROR: Unable to communicate with master!` or `ERROR: Unknown topic /image_raw`, re-run the network configuration step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2bd49b-6fb7-4712-8a7a-8eceaa04e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rostopic info /image_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fd0656-90b2-4c19-b442-a51dc7e4cd4d",
   "metadata": {},
   "source": [
    "### Prepare publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb316a30-05a0-4cac-9647-73e964d81872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyros\n",
    "import rospy\n",
    "from sensor_msgs.msg import Image\n",
    "from geometry_msgs.msg import Pose\n",
    "\n",
    "rospy.init_node(\"image_subscriber\")\n",
    "pub = rospy.Publisher('/body_pose', Pose, queue_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0265b7-b04e-4c0f-8103-fb88d2beaf1f",
   "metadata": {},
   "source": [
    "### Create widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9426d8-78e6-4291-89c5-dbca39f0ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "label_widget = widgets.IntText(value=88, description='tracked label')\n",
    "yaw_widget = widgets.FloatSlider(min = -0.3, max = 0.3, step = 0.005, description='yaw_increment')\n",
    "pitch_widget = widgets.FloatSlider(min = -0.2, max = 0.2, step = 0.005, description='pitch_increment')\n",
    "\n",
    "try:\n",
    "    sc = Sidecar(title='Object Following Output')\n",
    "    with sc:\n",
    "        display(widgets.VBox([\n",
    "            widgets.HBox([image_widget, pitch_widget]),\n",
    "            label_widget,\n",
    "            yaw_widget\n",
    "        ]))\n",
    "except:\n",
    "    display(widgets.VBox([\n",
    "        widgets.HBox([image_widget, pitch_widget]),\n",
    "        label_widget,\n",
    "        yaw_widget\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eea8b8-1ab0-4ec8-9428-762ea597bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from io import BytesIO\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "bridge = CvBridge()\n",
    "\n",
    "rospy.init_node(\"image_subscriber\")\n",
    "rate = rospy.Rate(5)\n",
    "\n",
    "min_conf_threshold = 0.5\n",
    "move_threshold = 10\n",
    "\n",
    "def callback(msg):\n",
    "    if rate.remaining() > rospy.Duration(0):\n",
    "        return\n",
    "    try:\n",
    "        image = bridge.imgmsg_to_cv2(msg, \"bgr8\")\n",
    "    except CvBridgeError as e:\n",
    "        rospy.logerr(\"CvBridge Error: {0}\".format(e))\n",
    "    # Load image and resize to expected shape [1xHxWx3]\n",
    "    imH, imW, _ = image.shape \n",
    "    image_resized = cv2.resize(image, (width, height))\n",
    "    input_data = np.expand_dims(image_resized, axis=0)\n",
    "\n",
    "    # Normalize pixel values if using a floating model (i.e. if model is non-quantized)\n",
    "    if floating_model:\n",
    "        input_data = (np.float32(input_data) - input_mean) / input_std\n",
    "\n",
    "    # Perform the actual detection by running the model with the image as input\n",
    "    interpreter.set_tensor(input_details[0]['index'],input_data)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Retrieve detection results\n",
    "    boxes = interpreter.get_tensor(output_details[boxes_idx]['index'])[0] # Bounding box coordinates of detected objects\n",
    "    classes = interpreter.get_tensor(output_details[classes_idx]['index'])[0]+1 # Class index of detected objects\n",
    "    scores = interpreter.get_tensor(output_details[scores_idx]['index'])[0] # Confidence of detected objects\n",
    "\n",
    "    # Loop over for first 5 detections and draw detection box if confidence is above minimum threshold\n",
    "    if sum(x>min_conf_threshold for x in scores) > 5:\n",
    "        print(\"too many objects!\")\n",
    "        return\n",
    "    direction = None\n",
    "    for i in range(len(scores)):\n",
    "        if ((scores[i] > min_conf_threshold) and (scores[i] <= 1.0)):\n",
    "\n",
    "            # Get bounding box coordinates and draw box\n",
    "            # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()\n",
    "            ymin = int(max(1,(boxes[i][0] * imH)))\n",
    "            xmin = int(max(1,(boxes[i][1] * imW)))\n",
    "            ymax = int(min(imH,(boxes[i][2] * imH)))\n",
    "            xmax = int(min(imW,(boxes[i][3] * imW)))\n",
    "            \n",
    "\n",
    "            cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)\n",
    "\n",
    "            # Draw label\n",
    "            object_name = labels[int(classes[i])] # Look up object name from \"labels\" array using class index\n",
    "            label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'\n",
    "            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 2.5, 4) # Get font size\n",
    "            label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n",
    "            cv2.rectangle(image, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Draw white box to put label text in\n",
    "            cv2.putText(image, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 2.5, (0, 0, 0), 4) # Draw label text\n",
    "            \n",
    " \n",
    "            if classes[i] == int(label_widget.value):\n",
    "                xcenter = (xmax+xmin)/2\n",
    "                ycenter = (ymax+ymin)/2\n",
    "                print(\"Label, (X, Y), max(X, Y) = {}, ({}, {}), ({}, {})\".format(object_name, xcenter, ycenter, imW, imH))\n",
    "                yaw_widget.value = 0.0003 * (imW/2 - xcenter) # 640px == 0.2 rad\n",
    "                pitch_widget.value = -0.0002 * (imH/2 - ycenter) # 480px == 0.1rad\n",
    "\n",
    "\n",
    "    _, frame = cv2.imencode('.jpg', cv2.resize(image, (int(width), int(height))), [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "    frame_buffer = BytesIO(frame)\n",
    "    image_widget.value = frame_buffer.getvalue()\n",
    "    last_time_stamp = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5fb8f8-28fe-43f9-938e-cccd718dfcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%thread_cell\n",
    "\n",
    "rate = rospy.Rate(20)\n",
    "while not rospy.is_shutdown():\n",
    "    pose = Pose()\n",
    "\n",
    "    yaw = yaw_widget.value\n",
    "    pitch = pitch_widget.value\n",
    "    roll = 0\n",
    "\n",
    "    cy = math.cos(yaw)\n",
    "    sy = math.sin(yaw)\n",
    "    cp = math.cos(pitch)\n",
    "    sp = math.sin(pitch)\n",
    "    cr = math.cos(roll)\n",
    "    sr = math.sin(roll)\n",
    "\n",
    "    pose.orientation.w = cy * cp * cr + sy * sp * sr\n",
    "    pose.orientation.x = cy * cp * sr - sy * sp * cr\n",
    "    pose.orientation.y = sy * cp * sr + cy * sp * cr\n",
    "    pose.orientation.z = sy * cp * cr - cy * sp * sr\n",
    "\n",
    "    pub.publish(pose)\n",
    "    rate.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d8562f-fc06-4633-bbdb-60a463da891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyros.subscribe(\"/image_raw\", Image, callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0543711-8389-49ae-ae2f-2e01224283d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rostopic info /body_pose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
